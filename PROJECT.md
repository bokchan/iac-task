# Make a service to run pipelines

## Main components

A high level description of the architecture

## webapp:

- Rest API for submitting to submit jobs for snakemake
  - submit job
  - retrieve status for job
  - retrieve list of running jobs
- backend service to orchestrate the processing pipeline via snakemake
  - store submitted jobs in the database


Allow the pipeline to be mocked as the scope is a PoC

## infrastructure

IaC to deploy the necessary infrastructure to AWS

## Implementation Plan (6-hour PoC)

### Core Scope: Pipeline Submission & Execution Service
**Goal**: Working REST API to submit and track mock Snakemake pipeline jobs

### Hour 1-2: FastAPI Application Setup
1. **Job Models & API Endpoints**
   ```python
   # Pydantic models
   - JobSubmission (input parameters)
   - JobStatus (id, status, created_at, updated_at)
   - JobList (paginated response)

   # Endpoints
   - POST /jobs - Submit new job
   - GET /jobs/{job_id} - Get job status
   - GET /jobs - List all jobs
   ```

2. **In-Memory Storage**
   - Simple dictionary/list to store job data
   - No database required for PoC
   - Job status: pending → running → completed/failed

3. **Mock Pipeline**
   - Python function that simulates Snakemake execution
   - Configurable delay (e.g., 10-30 seconds)
   - Random success/failure (80% success rate)

### Hour 3-4: Background Job Processing
1. **Background Task Worker**
   - Use FastAPI `BackgroundTasks` for simplicity
   - Process jobs asynchronously after submission
   - Update job status during execution

2. **Job Lifecycle**
   ```
   POST /jobs → Create job (pending)
                ↓
                Background worker picks up job
                ↓
                Update status (running)
                ↓
                Execute mock pipeline
                ↓
                Update status (completed/failed)
   ```

3. **Basic Error Handling**
   - Try/catch around pipeline execution
   - Store error messages in job object

### Hour 5-6: Testing & Deployment
1. **Local Testing**
   - Test all endpoints with curl/Postman
   - Submit multiple concurrent jobs
   - Verify status updates

2. **Documentation**
   - OpenAPI docs (auto-generated by FastAPI)
   - Simple README with usage examples

3. **Deployment Choice** (pick one):
   - **Option A**: Deploy to existing ECS infrastructure (reuse current setup)
   - **Option B**: Run locally with Docker Compose

### Minimal File Structure
```
webapp/
├── main.py              # FastAPI app with all endpoints
├── models.py            # Pydantic models
├── pipeline.py          # Mock pipeline execution
├── storage.py           # In-memory job storage
├── requirements.txt     # Dependencies
└── Dockerfile           # Existing file, no changes needed
```

### Technical Decisions (Simplified)
- ✅ **Storage**: In-memory (Python dict/list) - No database
- ✅ **Queue**: FastAPI BackgroundTasks - No SQS/Redis
- ✅ **Worker**: Same process as API - No separate worker service
- ✅ **Pipeline**: Mock Python function - No real Snakemake
- ✅ **Infrastructure**: Reuse existing ECS or Docker Compose

### What's Excluded (Out of Scope)
- ❌ Database (RDS/DynamoDB)
- ❌ Message queue (SQS)
- ❌ Separate worker service
- ❌ Authentication/Authorization
- ❌ Production monitoring
- ❌ CDK infrastructure changes
- ❌ Comprehensive testing
- ❌ Job persistence (data lost on restart)

### Deployment Options Comparison

#### Option A: Existing ECS Infrastructure (Recommended)
**Pros:**
- ✅ Already set up and working
- ✅ No new infrastructure needed
- ✅ Familiar deployment process (CDK + GitHub Actions)
- ✅ Production-like environment

**Cons:**
- ❌ Slightly slower iteration (deploy takes ~3-5 minutes)
- ❌ AWS costs (minimal for PoC)

**Deployment**: Update `webapp/main.py`, push to GitHub, existing pipeline deploys

#### Option B: Local Kubernetes (Docker Desktop)
**Pros:**
- ✅ Fast local iteration
- ✅ No AWS costs
- ✅ Learn K8s if that's a goal

**Cons:**
- ❌ Need to create K8s manifests (deployment, service, ingress)
- ❌ Additional setup time (~1-2 hours)
- ❌ Different from your existing infrastructure pattern
- ❌ More complexity for a simple PoC

**Setup Required:**
```yaml
# kubernetes/deployment.yaml
# kubernetes/service.yaml
# kubernetes/ingress.yaml (optional)
```

#### Option C: Docker Compose (Simplest)
**Pros:**
- ✅ Fastest setup (5 minutes)
- ✅ Simple and familiar
- ✅ No infrastructure complexity

**Cons:**
- ❌ Not representative of production
- ❌ Single machine only

**Setup**:
```yaml
# docker-compose.yml
version: '3.8'
services:
  api:
    build: ./webapp
    ports:
      - "8000:8000"
```

### Recommendation: Use Existing ECS Infrastructure

**Rationale:**
1. **Already built** - Your CDK infrastructure is production-ready
2. **6-hour constraint** - No time to learn K8s if unfamiliar
3. **Realistic** - Mirrors real deployment scenario
4. **Proven** - Your CI/CD pipeline works perfectly

**K8s would add:**
- Learning curve for K8s concepts (if new)
- Writing K8s manifests from scratch
- Debugging K8s-specific issues
- ~2 hours of setup time

**Verdict**: Only use K8s if you specifically want to learn it or plan to use it in production. Otherwise, stick with your working ECS setup.

### Implementation Checklist (6 hours)
- [ ] Hour 1: Create Pydantic models and basic endpoints
- [ ] Hour 2: Implement in-memory storage and mock pipeline
- [ ] Hour 3: Add background task processing
- [ ] Hour 4: Test job lifecycle and concurrent submissions
- [ ] Hour 5: Write basic documentation and examples
- [ ] Hour 6: Deploy and verify in chosen environment

### Success Criteria
✅ Can submit a job via POST /jobs
✅ Job status updates from pending → running → completed
✅ Can retrieve job status via GET /jobs/{id}
✅ Can list all jobs via GET /jobs
✅ Multiple concurrent jobs process correctly
✅ Mock pipeline executes with simulated delay

