# Make a service to run pipelines

## Main components

A high level description of the architecture

## webapp:

- Rest API for submitting to submit jobs for snakemake
  - submit job
  - retrieve status for job
  - retrieve list of running jobs
- backend service to orchestrate the processing pipeline via snakemake
  - store submitted jobs in the database


Allow the pipeline to be mocked as the scope is a PoC

## infrastructure

IaC to deploy the necessary infrastructure to AWS

## Implementation Plan (6-hour PoC)

### Core Scope: Pipeline Submission & Execution Service
**Goal**: Working REST API to submit and track mock Snakemake pipeline jobs

### AI-Assisted Development Strategy ğŸ¤–
**Leverage GitHub Copilot + Claude/ChatGPT throughout:**
- Generate Pydantic models and endpoint boilerplate
- Create test cases and mock data
- Debug issues and suggest fixes
- Generate documentation and examples
- Review code for best practices
- **Time savings**: 30-40% faster development

**Specific AI prompts to use:**
1. "Generate FastAPI endpoint for job submission with Pydantic models"
2. "Create in-memory storage class with thread-safe operations"
3. "Write pytest test cases for job lifecycle"
4. "Generate OpenAPI documentation examples"

### Hour 1-2: FastAPI Application Setup
1. **Job Models & API Endpoints**
   ```python
   # Pydantic models
   - JobSubmission (input parameters)
   - JobStatus (id, status, created_at, updated_at)
   - JobList (paginated response)

   # Endpoints
   - POST /jobs - Submit new job
   - GET /jobs/{job_id} - Get job status
   - GET /jobs - List all jobs
   ```

2. **In-Memory Storage Implementation**
   ```python
   # storage.py - Thread-safe in-memory job storage
   import threading
   from typing import Dict, List, Optional
   from datetime import datetime

   class JobStore:
       def __init__(self):
           self._jobs: Dict[str, dict] = {}
           self._lock = threading.Lock()

       def create(self, job_id: str, job_data: dict) -> dict:
           with self._lock:
               self._jobs[job_id] = job_data
               return job_data

       def get(self, job_id: str) -> Optional[dict]:
           with self._lock:
               return self._jobs.get(job_id)

       def update(self, job_id: str, updates: dict) -> Optional[dict]:
           with self._lock:
               if job_id in self._jobs:
                   self._jobs[job_id].update(updates)
                   return self._jobs[job_id]
               return None

       def list_all(self) -> List[dict]:
           with self._lock:
               return list(self._jobs.values())

   # Global instance
   job_store = JobStore()
   ```

   **How GET endpoints work with in-memory storage:**
   - âœ… `GET /jobs/{job_id}` - Looks up job in dictionary by ID
   - âœ… `GET /jobs` - Returns all jobs from dictionary values
   - âœ… Background tasks update job status in same dictionary
   - âœ… Thread-safe with locks for concurrent access
   - âš ï¸  Data lost on restart (acceptable for PoC)

   **This is NOT a mock** - it's a real working implementation:
   - Jobs are actually stored and retrievable
   - Status updates persist during application runtime
   - Multiple concurrent requests work correctly
   - Only limitation: no persistence across restarts

3. **Mock Pipeline**
   - Python function that simulates Snakemake execution
   - Configurable delay (e.g., 10-30 seconds)
   - Random success/failure (80% success rate)

### Hour 3-4: Background Job Processing
1. **Background Task Worker**
   - Use FastAPI `BackgroundTasks` for simplicity
   - Process jobs asynchronously after submission
   - Update job status during execution

2. **Job Lifecycle**
   ```
   POST /jobs â†’ Create job (pending)
                â†“
                Background worker picks up job
                â†“
                Update status (running)
                â†“
                Execute mock pipeline
                â†“
                Update status (completed/failed)
   ```

3. **Basic Error Handling**
   - Try/catch around pipeline execution
   - Store error messages in job object

### Hour 5-6: Testing & Deployment
1. **Local Testing**
   - Test all endpoints with curl/Postman
   - Submit multiple concurrent jobs
   - Verify status updates

2. **Documentation**
   - OpenAPI docs (auto-generated by FastAPI)
   - Simple README with usage examples

3. **Deployment Choice** (pick one):
   - **Option A**: Deploy to existing ECS infrastructure (reuse current setup)
   - **Option B**: Run locally with Docker Compose

### Minimal File Structure
```
webapp/
â”œâ”€â”€ main.py              # FastAPI app with all endpoints
â”œâ”€â”€ models.py            # Pydantic models
â”œâ”€â”€ pipeline.py          # Mock pipeline execution
â”œâ”€â”€ storage.py           # In-memory job storage
â”œâ”€â”€ requirements.txt     # Dependencies
â””â”€â”€ Dockerfile           # Existing file, no changes needed
```

### Technical Decisions (Simplified)
- âœ… **Storage**: In-memory (Python dict/list) - No database
- âœ… **Queue**: FastAPI BackgroundTasks - No SQS/Redis
- âœ… **Worker**: Same process as API - No separate worker service
- âœ… **Pipeline**: Mock Python function - No real Snakemake
- âœ… **Infrastructure**: Reuse existing ECS infrastructure (no CDK changes)
- âœ… **AI Tools**: GitHub Copilot + Claude/ChatGPT for rapid development

### Storage Solution Comparison: In-Memory vs PostgreSQL

#### Option 1: In-Memory Storage (Recommended for PoC)
**Implementation:**
```python
# Simple thread-safe dictionary
job_store = {"job_id": {status, data, timestamps}}
```

**Pros:**
- âœ… Zero setup time - works immediately
- âœ… No infrastructure changes needed
- âœ… Fast read/write operations (microseconds)
- âœ… Simple debugging and testing
- âœ… Perfect for PoC/demo

**Cons:**
- âŒ Data lost on restart/redeploy
- âŒ Not suitable for production
- âŒ Single container only (doesn't scale horizontally)
- âŒ No persistence for audit/history

**Time Required:** Included in 6-hour estimate

---

#### Option 2: PostgreSQL Database
**Implementation:**
```python
# SQLAlchemy models + database connection
class Job(Base):
    id = Column(UUID, primary_key=True)
    status = Column(String)
    created_at = Column(DateTime)
```

**Pros:**
- âœ… Persistent storage across restarts
- âœ… Production-ready solution
- âœ… Supports multiple containers/horizontal scaling
- âœ… Query capabilities (filter by status, date, etc.)
- âœ… Audit trail and history

**Cons:**
- âŒ Requires new CDK database stack
- âŒ More complex setup and testing
- âŒ Slower than in-memory (milliseconds vs microseconds)
- âŒ Additional costs (~$15-30/month for RDS)

**Additional Time Required:** +3-4 hours
- 1 hour: Create RDS stack in CDK (reuse VPC from existing infrastructure)
- 1 hour: SQLAlchemy models and database connection
- 0.5 hour: Update ECS task to include database credentials
- 0.5 hour: Test database connectivity and migrations
- 1 hour: Debugging and deployment

**Additional CDK Stack Required:**
```python
# infra/stacks/database_stack.py
class DatabaseStack(Stack):
    def __init__(self, scope, vpc_stack, config):
        self.db = rds.DatabaseInstance(
            self, "PostgresDB",
            engine=rds.DatabaseInstanceEngine.postgres(...),
            vpc=vpc_stack.vpc,
            vpc_subnets=vpc_stack.vpc.select_subnets(
                subnet_type=ec2.SubnetType.PRIVATE_WITH_EGRESS
            ),
            multi_az=False,  # Single AZ for PoC
            allocated_storage=20,
            instance_type=ec2.InstanceType.of(
                ec2.InstanceClass.T3,
                ec2.InstanceSize.MICRO
            ),
            removal_policy=RemovalPolicy.DESTROY,  # PoC only
        )
```

**Updated File Structure:**
```
webapp/
â”œâ”€â”€ main.py
â”œâ”€â”€ models.py
â”œâ”€â”€ database.py          # NEW: SQLAlchemy setup
â”œâ”€â”€ crud.py              # NEW: Database operations
â”œâ”€â”€ pipeline.py
â”œâ”€â”€ requirements.txt     # Add: sqlalchemy, psycopg2
â””â”€â”€ Dockerfile

infra/stacks/
â”œâ”€â”€ database_stack.py    # NEW: RDS PostgreSQL stack
â””â”€â”€ ... (existing stacks)
```

---

### Recommendation for 6-Hour PoC

**Use In-Memory Storage** because:
1. **Time constraint**: Database adds 3-4 hours = no time for testing/refinement
2. **PoC purpose**: Demonstrates functionality, not production readiness
3. **Working solution**: In-memory storage is fully functional, not a compromise
4. **Existing infrastructure**: No CDK changes needed - deploy immediately

**When to add PostgreSQL:**
- If PoC needs to demonstrate persistence
- If planning multi-container deployment
- If demonstrating production-readiness is critical
- If you have 9-10 hours instead of 6 hours

---

### What's Excluded (Out of Scope)
- âŒ Database (RDS/DynamoDB)
- âŒ Message queue (SQS)
- âŒ Separate worker service
- âŒ Authentication/Authorization
- âŒ Production monitoring
- âŒ CDK infrastructure changes
- âŒ Comprehensive testing
- âŒ Job persistence (data lost on restart)

### Deployment: Use Existing ECS Infrastructure âœ…

**Why this is optimal:**
1. âœ… **Zero infrastructure work** - No new CDK stacks needed
2. âœ… **Proven deployment** - Your CI/CD pipeline already works
3. âœ… **Fast iteration** - Push code, automatic deployment in 3-5 minutes
4. âœ… **Production-like** - Same environment pattern as production

**What gets reused from your existing setup:**
- VPC Stack (networking already configured)
- ECR Stack (push updated webapp image)
- GitHub OIDC Stack (authentication already set up)
- App Stack (ECS Fargate + ALB already deployed)
- GitHub Actions CI/CD (automatic build + deploy)

**Development workflow:**
1. Make code changes in `webapp/` directory
2. Commit and push to GitHub
3. Existing GitHub Actions workflow builds and deploys
4. Test endpoints on existing ALB URL
5. **AI assist**: Use Copilot to generate code, Claude to review

**No new infrastructure needed!** ğŸ‰

---

### Deployment Options Comparison (For Reference)

#### Option A: Existing ECS Infrastructure (âœ… RECOMMENDED)
**Pros:**
- âœ… Already set up and working
- âœ… No new infrastructure needed
- âœ… Familiar deployment process (CDK + GitHub Actions)
- âœ… Production-like environment

**Cons:**
- âŒ Slightly slower iteration (deploy takes ~3-5 minutes)
- âŒ AWS costs (minimal for PoC)

**Deployment**: Update `webapp/main.py`, push to GitHub, existing pipeline deploys

#### Option B: Local Kubernetes (Docker Desktop)
**Pros:**
- âœ… Fast local iteration
- âœ… No AWS costs
- âœ… Learn K8s if that's a goal

**Cons:**
- âŒ Need to create K8s manifests (deployment, service, ingress)
- âŒ Additional setup time (~1-2 hours)
- âŒ Different from your existing infrastructure pattern
- âŒ More complexity for a simple PoC

**Setup Required:**
```yaml
# kubernetes/deployment.yaml
# kubernetes/service.yaml
# kubernetes/ingress.yaml (optional)
```

#### Option C: Docker Compose (Simplest)
**Pros:**
- âœ… Fastest setup (5 minutes)
- âœ… Simple and familiar
- âœ… No infrastructure complexity

**Cons:**
- âŒ Not representative of production
- âŒ Single machine only

**Setup**:
```yaml
# docker-compose.yml
version: '3.8'
services:
  api:
    build: ./webapp
    ports:
      - "8000:8000"
```

### Recommendation: Use Existing ECS Infrastructure

**Rationale:**
1. **Already built** - Your CDK infrastructure is production-ready
2. **6-hour constraint** - No time to learn K8s if unfamiliar
3. **Realistic** - Mirrors real deployment scenario
4. **Proven** - Your CI/CD pipeline works perfectly

**K8s would add:**
- Learning curve for K8s concepts (if new)
- Writing K8s manifests from scratch
- Debugging K8s-specific issues
- ~2 hours of setup time

**Verdict**: Only use K8s if you specifically want to learn it or plan to use it in production. Otherwise, stick with your working ECS setup.

### Implementation Checklist (6 hours with AI assistance)
- [ ] Hour 1: AI-generate Pydantic models and basic endpoint structure
- [ ] Hour 2: Implement thread-safe in-memory storage with AI help
- [ ] Hour 2: Create mock pipeline function
- [ ] Hour 3: Add background task processing with FastAPI BackgroundTasks
- [ ] Hour 3-4: AI-generate test cases and test job lifecycle
- [ ] Hour 4: Test concurrent job submissions (AI-generated test script)
- [ ] Hour 5: AI-generate documentation and usage examples
- [ ] Hour 5: Update README with API examples
- [ ] Hour 6: Deploy to existing ECS via GitHub Actions
- [ ] Hour 6: Verify all endpoints work on deployed ALB

**AI Tools Usage Throughout:**
- GitHub Copilot: Code generation and completion
- Claude/ChatGPT: Architecture decisions, debugging, test generation
- Copilot Chat: Inline code explanations and refactoring suggestions

### Success Criteria
âœ… Can submit a job via POST /jobs
âœ… Job status updates from pending â†’ running â†’ completed
âœ… Can retrieve job status via GET /jobs/{id} (real-time from in-memory store)
âœ… Can list all jobs via GET /jobs (returns all stored jobs)
âœ… Multiple concurrent jobs process correctly (thread-safe storage)
âœ… Mock pipeline executes with simulated delay
âœ… Deployed to existing ECS infrastructure with zero infrastructure changes
âœ… AI-assisted development accelerates implementation by 30-40%

---

## FAQ: In-Memory Storage

**Q: How do GET endpoints work without a database?**
A: Jobs are stored in a Python dictionary with thread-safe locks. When you call GET /jobs/{id}, it looks up the job in memory. When background tasks update job status, they update the same in-memory dictionary. This works perfectly for a single-container PoC.

**Q: Is this just mocking the storage?**
A: No! This is real, functional storage - just not persistent. Jobs are actually created, updated, and retrieved. The only difference from a database is that data is lost on restart.

**Q: Can I test multiple jobs?**
A: Yes! You can submit dozens of jobs, they'll all be stored and tracked correctly during the application runtime.

**Q: What happens on ECS restart/redeploy?**
A: All job data is lost. For a PoC demo, simply submit new test jobs after deployment.

**Q: When should I add PostgreSQL?**
A: When you need:
- Persistence across restarts
- Multiple container instances (horizontal scaling)
- Historical job data and audit trails
- Production deployment
(Adds 3-4 hours to implementation time)

